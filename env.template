# ============================================
# AWS Configuration
# ============================================
# Required: Your AWS credentials
AWS_ACCESS_KEY_ID=your_aws_access_key_id_here
AWS_SECRET_ACCESS_KEY=your_aws_secret_access_key_here
AWS_REGION=us-east-1

# ============================================
# S3 Configuration
# ============================================
# Source bucket name (where CSV files are uploaded)
# Leave empty to use Terraform-generated bucket name
SOURCE_BUCKET=etl-pipeline-source-dev

# Destination bucket name (where processed Parquet files are stored)
# Leave empty to use Terraform-generated bucket name
DESTINATION_BUCKET=etl-pipeline-output-dev

# Source path (for local testing)
# Use S3 URI format: s3://bucket-name/input/file.csv
# Or local path: data/your_file.csv
SOURCE_PATH=s3://your-source-bucket/input/your_file.csv

# Source type: 's3' or 'local'
SOURCE_TYPE=s3

# Output prefix for processed data in destination bucket
OUTPUT_PREFIX=processed_data

# ============================================
# Spark Configuration
# ============================================
# Spark master URL (for local execution)
SPARK_MASTER=local[*]

# Spark driver memory
SPARK_DRIVER_MEMORY=2g

# Spark executor memory
SPARK_EXECUTOR_MEMORY=2g

# ============================================
# Monitoring & Logging
# ============================================
# CloudWatch log group name
CLOUDWATCH_LOG_GROUP=etl-pipeline

# Enable CloudWatch logging (true/false)
CLOUDWATCH_ENABLED=true

# ============================================
# Secrets Management (Optional)
# ============================================
# HashiCorp Vault configuration (if using Vault instead of environment variables)
# VAULT_ADDR=https://your-vault-address:8200
# VAULT_TOKEN=your_vault_token_here
# USE_VAULT=false

# ============================================
# Notes
# ============================================
# 1. For Lambda function: DESTINATION_BUCKET, AWS_REGION, OUTPUT_PREFIX, and CLOUDWATCH_LOG_GROUP
#    are automatically set by Terraform - you don't need to configure them here for Lambda
# 
# 2. For local execution: Set SOURCE_PATH, SOURCE_TYPE, and DESTINATION_BUCKET
#
# 3. After Terraform deployment, get bucket names with:
#    terraform output source_bucket_name
#    terraform output destination_bucket_name

